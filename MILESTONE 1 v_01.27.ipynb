{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import warnings\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import display_html \n",
    "import altair as alt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Sources:\n",
    "# https://crashviewer.nhtsa.dot.gov/CrashAPI\n",
    "# https://hifld-geoplatform.opendata.arcgis.com/datasets/hospitals/data?selectedAttribute=BEDS Hospital Data\n",
    "# https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function declaration cell\n",
    "\n",
    "def radius(Lat1, Lon1, Lat2, Lon2):\n",
    "    \"\"\" \n",
    "    Calculates the distance between 2 coordinates. \n",
    "  \n",
    "    Process the distance between 2 coordinates based on the Harversine formula.\n",
    "    If you want to learn more about the math behind the Harversine plese refer to:\n",
    "    http://www.movable-type.co.uk/scripts/latlong.html?from=48.6093070,-122.4259880&to=48.5928360,-122.4216130\n",
    "    http://janmatuschek.de/LatitudeLongitudeBoundingCoordinates\n",
    "  \n",
    "    Parameters: \n",
    "    Lat1 (float): Latitude of point 1 in radians\n",
    "    Lon1 (float): Longitude of point 1 in radians\n",
    "    Lat2 (float): Latitude of point 2 in radians\n",
    "    Lon2 (float): Longitude of point 2 in radians\n",
    "    \n",
    "    Returns: \n",
    "    Float: Distance between point 1 and point 2 in Kilometers\n",
    "  \n",
    "    \"\"\"\n",
    "    return np.arccos((np.sin(Lat1) * np.sin(Lat2)) + \n",
    "                     (np.cos(Lat1) * np.cos(Lat2) * np.cos(Lon2 - (Lon1)))) * 6371\n",
    "\n",
    "\n",
    "# Function to filter cities in data frame\n",
    "# Input DF has to have lat and lon in radius with name 'Lat_rad' and 'Lon_rad'\n",
    "def filter_top_cities(DF):\n",
    "    \"\"\" \n",
    "    Returns a filtered data frame with all 317 cities. \n",
    "  \n",
    "    Returns a filtered data frame based in location from top cities for all the instances in the radius of\n",
    "    the city.\n",
    "  \n",
    "    Parameters: \n",
    "    DF (pandas dataframe): Data frame containing latitude and longitude in radians.\n",
    "    \n",
    "    Returns: \n",
    "    dataframe : Data frame with filtered rows containing instances where the location is whitin the radius of the\n",
    "    top cities.\n",
    "  \n",
    "    \"\"\"\n",
    "    return_df = pd.DataFrame()\n",
    "    for i in range(len(top_cities)): # All top cities df creation\n",
    "        rad = np.sqrt(top_cities['Land'][i]) # Calculate the radius for the city\n",
    "        df = pd.DataFrame() # Transition DF\n",
    "        df = DF[radius(top_cities['Lat_rad'][i], top_cities['Lon_rad'][i],\n",
    "                         DF['Lat_rad'], DF['Lon_rad']) <= rad]\n",
    "        df['Top_City'] = top_cities['City'][i]\n",
    "        df['Pop'] = top_cities['2019estimate'][i]\n",
    "        df['Rank'] = top_cities['2019rank'][i]\n",
    "        return_df = return_df.append(df)\n",
    "    return_df.reset_index(inplace=True)\n",
    "    return return_df\n",
    "\n",
    "def filter_topten_cities(DF): #Filter top ten cities\n",
    "    \"\"\" \n",
    "    Returns a filtered data frame with top ten cities only. \n",
    "  \n",
    "    Returns a filtered data frame based in location from top ten cities for all the instances in the radius of\n",
    "    the city.\n",
    "  \n",
    "    Parameters: \n",
    "    DF (pandas dataframe): Data frame containing latitude and longitude in radians.\n",
    "    \n",
    "    Returns: \n",
    "    dataframe : Data frame with filtered rows containing instances where the location is whitin the radius of the\n",
    "    top ten cities.\n",
    "  \n",
    "    \"\"\"\n",
    "    return_df = pd.DataFrame()\n",
    "    for i in range(len(topten_cities)): # All top cities df creation\n",
    "        rad = np.sqrt(topten_cities['Land'][i]) # Calculate the radius for the city\n",
    "        df = pd.DataFrame() # Transition DF\n",
    "        df = DF[radius(topten_cities['Lat_rad'][i], topten_cities['Lon_rad'][i],\n",
    "                         DF['Lat_rad'], DF['Lon_rad']) <= rad]\n",
    "        df['Top_City'] = topten_cities['City'][i]\n",
    "        df['Pop'] = topten_cities['2019estimate'][i]\n",
    "        df['Rank'] = topten_cities['2019rank'][i]\n",
    "        return_df = return_df.append(df)\n",
    "    return_df.reset_index(inplace=True)\n",
    "    return return_df\n",
    "\n",
    "# Function to format large numbers in a human readable way\n",
    "def human_format(num):\n",
    "    \"\"\" \n",
    "    Returns a human readable format for long numbers. \n",
    "  \n",
    "    For numbers that are long like 1304678, it will return a string of 1.30M.\n",
    "  \n",
    "    Parameters: \n",
    "    num (float): Number to be converted in human format.\n",
    "    \n",
    "    Returns: \n",
    "    string : String with a human readable format.\n",
    "  \n",
    "    \"\"\"\n",
    "    magnitude = 0\n",
    "    while abs(num) >= 1000:\n",
    "        magnitude += 1\n",
    "        num /= 1000.0\n",
    "    # add more suffixes if you need them\n",
    "    return '%.2f%s' % (num, ['', 'K', 'M', 'G', 'T', 'P'][magnitude])\n",
    "\n",
    "# Function to convert seconds to hour:minutes:seconds\n",
    "def convert(seconds): \n",
    "    \"\"\" \n",
    "    Convert seconds to hour, minutes and seconds. \n",
    "  \n",
    "    Convert seconds into a format that it is readable and comprehensible for humans.\n",
    "  \n",
    "    Parameters: \n",
    "    seconds (float): Number to be converted in human format.\n",
    "    \n",
    "    Returns: \n",
    "    string : String with a human readable format of HH:MM:SS.\n",
    "  \n",
    "    \"\"\"\n",
    "    seconds = seconds % (24 * 3600) \n",
    "    hour = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "      \n",
    "    return \"%d:%02d:%02d\" % (hour, minutes, seconds) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# So the dataset is retrieved from: https://crashviewer.nhtsa.dot.gov/CrashAPI\n",
    "#GET FARS data from accident, pbtype, and vehicle tables \n",
    "fars_acc2018 = pd.read_csv('data/FARS/FARS2018/ACCIDENT.csv')\n",
    "fars_acc2017 = pd.read_csv('data/FARS/FARS2017/ACCIDENT.csv')\n",
    "fars_acc2016 = pd.read_csv('data/FARS/FARS2016/ACCIDENT.csv')\n",
    "\n",
    "fars_PB2018 = pd.read_csv('data/FARS/FARS2018/PBTYPE.csv')\n",
    "fars_PB2017 = pd.read_csv('data/FARS/FARS2017/PBTYPE.csv')\n",
    "fars_PB2016 = pd.read_csv('data/FARS/FARS2016/PBTYPE.csv')\n",
    "\n",
    "fars_veh2018 = pd.read_csv('data/FARS/FARS2018/VEHICLE.csv',encoding= 'unicode_escape')\n",
    "fars_veh2017 = pd.read_csv('data/FARS/FARS2017/VEHICLE.csv',encoding= 'unicode_escape')\n",
    "fars_veh2016 = pd.read_csv('data/FARS/FARS2016/VEHICLE.csv',encoding= 'unicode_escape')\n",
    "\n",
    "#Load GLC data to add city and county to FARS data\n",
    "GLC = pd.read_excel('data/FRPP_GLC_-_United_StatesDEC72020.xlsx',  engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join FARS accident and vehicle tables on state and st_case\n",
    "fars_acc_veh_2018 = pd.merge(fars_acc2018, fars_veh2018,  how='left', left_on=['STATE','ST_CASE'], right_on = ['STATE','ST_CASE'])\n",
    "fars_acc_veh_2017 = pd.merge(fars_acc2017, fars_veh2017,  how='left', left_on=['STATE','ST_CASE'], right_on = ['STATE','ST_CASE'])\n",
    "fars_acc_veh_2016 = pd.merge(fars_acc2016, fars_veh2016,  how='left', left_on=['STATE','ST_CASE'], right_on = ['STATE','ST_CASE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join FARS accident and vehicle tables on state and st_case\n",
    "fars_all_2018 = pd.merge(fars_acc_veh_2018, fars_PB2018,  how='left', left_on=['STATE','ST_CASE'], right_on = ['STATE','ST_CASE'])\n",
    "fars_all_2017 = pd.merge(fars_acc_veh_2017, fars_PB2017,  how='left', left_on=['STATE','ST_CASE'], right_on = ['STATE','ST_CASE'])\n",
    "fars_all_2016 = pd.merge(fars_acc_veh_2016, fars_PB2016,  how='left', left_on=['STATE','ST_CASE'], right_on = ['STATE','ST_CASE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_3yrs_withPB = fars_all_2018.append([fars_all_2017, fars_all_2016])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#One more step for FARS, get city name and county name from GLC\n",
    "#As some city level data can't be matched, so we match the city first, and then match state again \n",
    "#to replace the nan value if city couldn't be matched.\n",
    "\n",
    "#Load GLC data to add city and county to FARS data\n",
    "GLC = pd.read_excel('data/FRPP_GLC_-_United_StatesDEC72020.xlsx',  engine='openpyxl')\n",
    "\n",
    "# Remove duplicates on GLC df to avoid duplicates when merging\n",
    "right_key = ['State Code','County Code','City Code']\n",
    "GLC.drop_duplicates(subset=right_key, keep = 'first', inplace = True) \n",
    "\n",
    "#Join operation\n",
    "FARS_GLC=pd.merge(FARS_3yrs_withPB, GLC[['State Code', 'State Name', 'County Code','County Name',\n",
    "                                         'City Code','City Name']],  \n",
    "                  how='left', left_on=['STATE','COUNTY','CITY'], \n",
    "                  right_on = ['State Code','County Code','City Code'], validate = 'm:1')\n",
    "len(FARS_GLC)\n",
    "FARS_GLC\n",
    "\n",
    "# Remove duplicates again on GLC to match State and County only\n",
    "right_key = ['State Code','County Code']\n",
    "GLC.drop_duplicates(subset=right_key, keep = 'first', inplace = True) \n",
    "\n",
    "# Drop columns to avoid double columns with same info\n",
    "FARS_GLC.drop(columns=['State Code', 'State Name', 'County Code','County Name'], inplace = True)\n",
    "\n",
    "FARS_GLC2=pd.merge(FARS_GLC, GLC[['State Code','County Code','County Name','State Name']],  \n",
    "                   how='left', left_on=['STATE', 'COUNTY'], \n",
    "                   right_on = ['State Code', 'County Code'], validate = 'm:1')\n",
    "# FARS_GLC[['COUNTY','STATE','CITY','State Code', 'State Name', 'County Code','County Name','City Code','City Name']].head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explanation?\n",
    "FARS_16_17_18=FARS_GLC2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET CRSS data from accident, pbtype, and vehicle tables \n",
    "crss_acc2018 = pd.read_csv('data/CRSS/CRSS2018/ACCIDENT.csv')\n",
    "crss_acc2017 = pd.read_csv('data/CRSS/CRSS2017/ACCIDENT.csv')\n",
    "crss_acc2016 = pd.read_csv('data/CRSS/CRSS2016/ACCIDENT.csv')\n",
    "\n",
    "crss_PB2018 = pd.read_csv('data/CRSS/CRSS2018/PBTYPE.csv')\n",
    "crss_PB2017 = pd.read_csv('data/CRSS/CRSS2017/PBTYPE.csv')\n",
    "crss_PB2016 = pd.read_csv('data/CRSS/CRSS2016/PBTYPE.csv')\n",
    "\n",
    "crss_veh2018 = pd.read_csv('data/CRSS/CRSS2018/VEHICLE.csv',encoding= 'unicode_escape')\n",
    "crss_veh2017 = pd.read_csv('data/CRSS/CRSS2017/VEHICLE.csv',encoding= 'unicode_escape')\n",
    "crss_veh2016 = pd.read_csv('data/CRSS/CRSS2016/VEHICLE.csv',encoding= 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join CRSS accident and vehicle tables on state and st_case\n",
    "crss_acc_veh_2018 = pd.merge(crss_acc2018, crss_veh2018,  how='left', left_on=['CASENUM'], right_on = ['CASENUM'])\n",
    "crss_acc_veh_2017 = pd.merge(crss_acc2017, crss_veh2017,  how='left', left_on=['CASENUM'], right_on = ['CASENUM'])\n",
    "crss_acc_veh_2016 = pd.merge(crss_acc2016, crss_veh2016,  how='left', left_on=['CASENUM'], right_on = ['CASENUM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crss_all_2018 = pd.merge(crss_acc_veh_2018, crss_PB2018,  how='left', left_on=['CASENUM','VEH_NO'], right_on = ['CASENUM','VEH_NO'])\n",
    "crss_all_2017 = pd.merge(crss_acc_veh_2017, crss_PB2017,  how='left', left_on=['CASENUM','VEH_NO'], right_on = ['CASENUM','VEH_NO'])\n",
    "crss_all_2016 = pd.merge(crss_acc_veh_2016, crss_PB2016,  how='left', left_on=['CASENUM','VEH_NO'], right_on = ['CASENUM','VEH_NO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explanation?\n",
    "CRSS_16_17_18 = crss_all_2018.append([crss_all_2017, crss_all_2016])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Scrap to collect biggest US cities by population.\n",
    "# Get URL, request HTML and create soup\n",
    "URL = 'https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population'\n",
    "page = requests.get(URL)\n",
    "page.content\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# Find all tables and table for interest is table 4, extract it and send it to DF\n",
    "table = soup.find_all('table')\n",
    "top_cities = pd.read_html(str(table))[4]\n",
    "\n",
    "#Extract Lat and Long independently to plot cities and convert to float\n",
    "top_cities['Lat'] = top_cities['Location'].str.extract('(\\d+\\.\\d+)').astype(float)\n",
    "top_cities['Lon'] = (top_cities['Location'].str.extract('\\s(\\d+\\.\\d+)').astype(float))*-1\n",
    "\n",
    "#Convert Lat and Long to radians to faciliate creating a radius for the city\n",
    "top_cities['Lat_rad'] = top_cities['Lat'] * np.pi / 180\n",
    "top_cities['Lon_rad'] = top_cities['Lon'] * np.pi / 180\n",
    "\n",
    "# Get land area in km2 (Clean and extract number only)\n",
    "top_cities['Land'] = top_cities['2016 land area.1'].str.extract('([\\d,]+\\.\\d+)').replace(',','')\n",
    "top_cities['Land'] = top_cities['Land'].str.replace(',','').astype(float)\n",
    "\n",
    "#Clean City name\n",
    "top_cities['City'] = top_cities['City'].str.replace(r\"\\[.*\\]\", '')\n",
    "# top_cities\n",
    "\n",
    "topten_cities = top_cities.loc[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Hospital data\n",
    "hospitals = pd.read_csv('data/Hospitals.csv')\n",
    "# Filter out Closed hospitals\n",
    "hospitals = hospitals.loc[hospitals['STATUS'] == 'OPEN']\n",
    "\n",
    "#Convert Latitude and Longitude to radiasn\n",
    "hospitals['Lat_rad'] = hospitals['LATITUDE'] * np.pi / 180\n",
    "hospitals['Lon_rad'] = hospitals['LONGITUDE'] * np.pi / 180\n",
    "\n",
    "hospitals = hospitals.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##PLOT a count of accidents by year and month\n",
    "yr_month_count=FARS_16_17_18.groupby(['YEAR','MONTH_x']).ST_CASE.nunique().reset_index().rename(columns={'ST_CASE':'count'})\n",
    "Months_name = {1:\"Jan\", 2:\"Feb\", 3:\"Mar\", 4:\"Apr\", 5:\"May\", 6:\"Jun\", \n",
    "          7:\"Jul\", 8:\"Aug\", 9:\"Sep\", 10:\"Oct\", 11:\"Nov\", 12:\"Dec\"}\n",
    "yr_month_count=yr_month_count.replace({\"MONTH_x\": Months_name})\n",
    "\n",
    "\n",
    "months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \n",
    "          \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "yr_month_count['month'] = pd.Categorical(yr_month_count['MONTH_x'], categories=months, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison of number of fatal accidents from 2016 to 2018\n",
    "months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \n",
    "          \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "yr_month_count['month'] = pd.Categorical(yr_month_count['MONTH_x'], categories=months, ordered=True)\n",
    "plt.figure(figsize=(20,9))\n",
    "ax =sns.lineplot(data = yr_month_count, x='month',y='count', hue='YEAR',style=\"YEAR\",ci=None,palette=\"Paired\",markers=True)\n",
    "ax.set_title('Comparing total number of accidents per month, 2016 To 2018',fontsize=20)\n",
    "sns.set(font_scale=2)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb=FARS_16_17_18[FARS_16_17_18['PBPTYPE'].notna()]\n",
    "yr_month_count_pb=pb.groupby(['YEAR','MONTH_x']).ST_CASE.nunique().reset_index().rename(columns={'ST_CASE':'count'})\n",
    "\n",
    "Months_name = {1:\"Jan\", 2:\"Feb\", 3:\"Mar\", 4:\"Apr\", 5:\"May\", 6:\"Jun\", \n",
    "          7:\"Jul\", 8:\"Aug\", 9:\"Sep\", 10:\"Oct\", 11:\"Nov\", 12:\"Dec\"}\n",
    "yr_month_count_pb=yr_month_count_pb.replace({\"MONTH_x\": Months_name})\n",
    "\n",
    "months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \n",
    "          \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "yr_month_count_pb['month'] = pd.Categorical(yr_month_count_pb['MONTH_x'], categories=months, ordered=True)\n",
    "plt.figure(figsize=(20,9))\n",
    "ax =sns.lineplot(data = yr_month_count_pb, x='month',y='count', hue='YEAR',style=\"YEAR\",ci=None,palette=\"Paired\",markers=True)\n",
    "ax.set_title('Comparing total number of accidents involves Pedestrian/Bikes per month, 2016 To 2018',fontsize=20)\n",
    "sns.set(font_scale=2)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create copy of data\n",
    "FARS=FARS_16_17_18.copy()\n",
    "CRSS=CRSS_16_17_18.copy()\n",
    "\n",
    "#Convert Latitude and Longitude to radians\n",
    "FARS['Lat_rad'] = FARS['LATITUDE'] * np.pi / 180\n",
    "FARS['Lon_rad'] = FARS['LONGITUD'] * np.pi / 180\n",
    "\n",
    "#Replace integer with actual values\n",
    "Light_Cond = {1:\"Daylight\", 2:\"Dark – Not Lighted\", 3:\"Dark – Lighted\", 4:\"Dawn\", 5:\"Dusk\", 6:\"Dark – Unknown Lighting\", \n",
    "          7:\"Other\", 8:\"Not Reported\", 9:\"Unknown/Reported as Unknown\", 10:\"Oct\", 11:\"Nov\", 12:\"Dec\"}\n",
    "FARS=FARS.replace({\"LGT_COND\": Light_Cond})\n",
    "CRSS=CRSS.replace({\"LGT_COND\": Light_Cond})\n",
    "\n",
    "Alc_inv = {1:\"Alcohol Involved\", 2:\"No Alcohol Involved\",  8:\"No Applicable Person\",9:\"Unknown\"}\n",
    "CRSS=CRSS.replace({\"ALCOHOL\": Alc_inv})\n",
    "\n",
    "Weather_str={0:\"No Additional Atmospheric Conditions\", 1:\"Clear\", 2:\"Rain\", 3:\"Sleet or Hail\", 4:\"Snow\", \n",
    "         5:\"Fog, Smog, Smoke\", 6:\"Severe Crosswinds\", \n",
    "        7:\"Blowing Sand, Soil, Dirt\", 8:\"Other\",  \n",
    "        10:\"Cloudy\", 11:\"Blowing Snow\", 12:\"Freezing Rain or Drizzle\",\n",
    "        98:\"Unknown/Reported as Unknown\",\n",
    "        99:\"Unknown/Reported as Unknown\"}\n",
    "FARS=FARS.replace({\"WEATHER\": Weather_str})\n",
    "CRSS=CRSS.replace({\"WEATHER\": Weather_str})\n",
    "\n",
    "Manner_collison={0:\"Not Collision with Motor Vehicle in Transport\", 1:\"Front-to-Rear\", 2:\"Front-to-Front\",\n",
    "                 3:\"Angle – Front-to-Side, Same Direction\", 4:\"Angle – Front-to-Side, Opposite Direction\", \n",
    "         5:\"Angle – Front-to-Side, Right Angle (Includes Broadside)\", \n",
    "        6:\"Angle – Front-to-Side/Angle-Direction Not Specified\", \n",
    "        7:\"Sideswipe – Same Direction\", 8:\"Sideswipe – Opposite Direction\",\n",
    "        9:\"Rear-to-Side\",\n",
    "        10:\"Rear-to-Rear\", 11:\"Other (End-Swipes and Others)\", \n",
    "        98:\"Not Reported\",\n",
    "        99:\"Unknown/Reported as Unknown\"}\n",
    "FARS=FARS.replace({\"MAN_COLL_x\": Manner_collison})\n",
    "CRSS=CRSS.replace({\"MAN_COLL_x\": Manner_collison})\n",
    "\n",
    "\n",
    "Rel_Roads={1:\"On Roadway\", 2:\"On Shoulder\", 3:\"On Median\", 4:\"On Roadside\", \n",
    "         5:\"Outside Trafficway\", 6:\"Off Roadway – Location Unknown\", \n",
    "        7:\"In Parking Lane/Zone\", 8:\"Gore\",  \n",
    "        10:\"Separator\", 11:\"Continuous Left Turn Lane\", \n",
    "        12:\"Unknown/Reported as Unknown\",\n",
    "        98:\"Not Reported\",\n",
    "        99:\"Unknown/Reported as Unknown\"}\n",
    "\n",
    "FARS=FARS.replace({\"REL_ROAD\": Rel_Roads})\n",
    "CRSS=CRSS.replace({\"REL_ROAD\": Rel_Roads})\n",
    "\n",
    "\n",
    "Level_Damage_Veh={0:\"No Damage\", 2:\"Minor Damage\", 4:\"Functional Damage\", \n",
    "         6:\"Disabling Damage\", 8:\"Not Reported\", \n",
    "     9:\"Reported as Unknown\"\n",
    "        }\n",
    "\n",
    "FARS=FARS.replace({\"DEFORMED\": Level_Damage_Veh})\n",
    "CRSS=CRSS.replace({\"DEFORMED\": Level_Damage_Veh})\n",
    "\n",
    "\n",
    "Haz_Involve={1:\"No\", 2:\"Yes\"\n",
    "        }\n",
    "\n",
    "FARS=FARS.replace({\"HAZ_INV\": Haz_Involve})\n",
    "CRSS=CRSS.replace({\"HAZ_INV\": Haz_Involve})\n",
    "\n",
    "Roll_over={0:\"No Rollover\", 1:\"Rollover, Tripped by Object/Vehicle Subsequent Event\",\n",
    "           2:\"Rollover, Untripped\",\n",
    "           9:\"Rollover, Unknown Type\"\n",
    "        }\n",
    "\n",
    "FARS=FARS.replace({\"ROLLOVER\": Roll_over})\n",
    "CRSS=CRSS.replace({\"ROLLOVER\": Roll_over})\n",
    "\n",
    "\n",
    "Fire={0:\"No or Not Reported\", 1:\"Yes\"}\n",
    "\n",
    "FARS=FARS.replace({\"FIRE_EXP\": Fire})\n",
    "CRSS=CRSS.replace({\"FIRE_EXP\": Fire})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The parts below is for fatal accidents analysis\n",
    "\n",
    "Sur_type={0:\"Non-Trafficway or Driveway Access\",\n",
    "         1:\"Concrete\",\n",
    "         2:\"Blacktop, Bituminous, or Asphalt\",\n",
    "         3:\"Brick or Block\",\n",
    "         4:\"Slag, Gravel or Stone\",\n",
    "         5:\"Dirt\",\n",
    "         7:\"Other\",\n",
    "         8:\"Not Reported\",\n",
    "         9:\"Unkown/Reported as Unknown\"}\n",
    "\n",
    "FARS=FARS.replace({\"VPAVETYP\": Sur_type})\n",
    "\n",
    "Surf_cond={0:\"Non-Trafficway Area or Driveway Access\",\n",
    "          1:\"Dry\",\n",
    "          2:\"Wet\",\n",
    "          3:\"Snow\",\n",
    "          4:\"Ice/Frost\",\n",
    "          5:\"Sand\",\n",
    "          6:\"Water (Standing or Moving)\",\n",
    "          7:\"Oil\",\n",
    "          8:\"Other\",\n",
    "          10:\"Slush\",\n",
    "          11:\"Mud, Dirt, Gravel\",\n",
    "          98:\"Not Reported\",\n",
    "          99:\"Unknown/Reported as Unknown\"}\n",
    "\n",
    "FARS=FARS.replace({\"VSURCOND\": Surf_cond}) \n",
    "\n",
    "\n",
    "Vehicle_make={1:\"American Motors\",\n",
    "             2:\"Jeep/Kaiser-Jeep/Willys Jeep\",\n",
    "             3:\"AM General\",\n",
    "             6:\"Chrysler\",\n",
    "             7:\"Dodge\",\n",
    "             8:\"Imperial\",\n",
    "             9:\"Plymouth\",\n",
    "             10:\"Eagle\",\n",
    "             12:\"Ford\",\n",
    "             13:\"Lincoln\",\n",
    "             14:\"Mercury\",\n",
    "             18:\"Buick/Opel\",\n",
    "             19:\"Cadillac\",\n",
    "             20:\"Chevrolet\",\n",
    "             21:\"Oldsmobile\",\n",
    "             22:\"Pontiac\",\n",
    "             23:\"GMC\",\n",
    "             24:\"Saturn\",\n",
    "             25:\"Grumman\",\n",
    "             26:\"Coda (Since 2013)\",\n",
    "             29:\"Other Domestic (Avanti Checker DeSoto Excalibur Hudson Packard Panoz Saleen Studebaker Stutz Tesla (Since 2014))\",\n",
    "             30:\"30 Volkswagen\",\n",
    "             31:\"Alfa Romeo\",\n",
    "             32:\"Audi\",\n",
    "             33:\"Austin/Austin Healey\",\n",
    "             34:\"BMW\",\n",
    "             35:\"Datsun/Nissan\",\n",
    "             36:\"Fiat\",\n",
    "             37:\"Honda\",\n",
    "             38:\"Isuzu\",\n",
    "             39:\"Jaguar\",\n",
    "             40:\"Lancia\",\n",
    "             41:\"Mazda\",\n",
    "             42:\"Mercedes-Benz\",\n",
    "             43:\"MG\",\n",
    "             44:\"Peugeot\",\n",
    "             45:\"Porsche\",\n",
    "             46:\"Renault\",\n",
    "             47:\"Saab\",\n",
    "             48:\"Subaru\",\n",
    "             49:\"Toyota\",\n",
    "             50:\"Triumph\",\n",
    "             51:\"Volvo\",\n",
    "             52:\"Mitsubishi\",\n",
    "             53:\"Suzuki\",\n",
    "             54:\"Acura\",\n",
    "             55:\"Hyundai\",\n",
    "             56:\"Merkur\",\n",
    "             57:\"Yugo\",\n",
    "             58:\"Infiniti\",\n",
    "             59:\"Lexus\",\n",
    "             60:\"Daihatsu\",\n",
    "             61:\"Sterling\",\n",
    "             62:\"Land Rover\",\n",
    "             63:\"Kia\",\n",
    "             64:\"Daewoo\",\n",
    "             65:\"Smart (Since 2010)\",\n",
    "             66:\"Mahindra (2011-2013)\",\n",
    "             67:\"Scion (Since 2012)\",\n",
    "             69:\"Other Imports (such as Aston Martin Bentley Bertone Bricklin Bugatti Caterham Citroen DeLorean Desta Ferrari Lamborghini Mini Cooper Morgan\",\n",
    "             70:\"BSA\",\n",
    "             71:\"Ducati\",\n",
    "             72:\"Harley-Davidson\",\n",
    "             73:\"Kawasaki\",\n",
    "             74:\"Moto Guzzi\",\n",
    "             75:\"Norton\",\n",
    "             76:\"Yamaha\",\n",
    "             77:\"Victory\",\n",
    "             78:\"Other Make Moped (Since 2010)\",\n",
    "             79:\"Other Make Motored Cycle (Since 2010)\",\n",
    "             80:\"Brockway\",\n",
    "             81:\"Diamond Reo/Reo\",\n",
    "             82:\"Freightliner\",\n",
    "             83:\"FWD\",\n",
    "             84:\"International Harvester/Navistar\",\n",
    "             85:\"Kenworth\",\n",
    "             86:\"Mack\",\n",
    "             87:\"Peterbilt\",\n",
    "             88:\"Iveco/Magirus\",\n",
    "             89:\"White/Autocar, White/GMC\",\n",
    "             90:\"Bluebird\",\n",
    "             91:\"Eagle Coach\",\n",
    "             92:\"Gillig\",\n",
    "             93:\"MCI\",\n",
    "             94:\"Thomas Built\",\n",
    "             97:\"Not Reported (Since 2010)\",\n",
    "             98:\"Other Make Auto-Union-DKW Carpenter Collins Bus DINA Divco Hino Mid Bus Neoplan Orion Oshkosh Scania Sterling UD Van Hool Western Star\",\n",
    "             99:\"Unknown Make\"}\n",
    "\n",
    "\n",
    "FARS=FARS.replace({\"MAKE\": Vehicle_make})              \n",
    "     \n",
    "Bodytype={1:\"Convertible (Excludes Sunroof, T-Bar)\", \n",
    "          2:\"2-Door Sedan/Hardtop/Coupe\",         \n",
    "          3:\"3-Door/2-Door Hatchback\",\n",
    "          4:\"4-Door Sedan/Hardtop\",\n",
    "          5:\"5-Door/4-Door Hatchback\",\n",
    "          6:\"Station Wagon (Excluding Van and Truck-Based)\",\n",
    "          7: \"Hatchback, Number of Doors Unknown\",\n",
    "          8:\"Sedan/Hardtop, Number of Doors Unknown (Since 1994)\",\n",
    "          9:\"Other or Unknown Automobile Type (Since 1994)\",\n",
    "          10:\"Auto-Based Pickup\",\n",
    "          11:\"Auto-Based Panel (Cargo Station Wagon, Auto-Based Ambulance or Hearse)\",\n",
    "          12:\"Large Limousine – More Than Four Side Doors or Stretch Chassis\",\n",
    "          13:\"Three-Wheel Automobile or Automobile Derivative\",\n",
    "          14:\"Compact Utility (ANSI D-16 Utility Vehicle Categories “Small” and “Midsize”)\",\n",
    "          15:\"Large Utility (ANSI D-16 Utility Vehicle Categories “Full Size” and “Large”)\",\n",
    "          16:\"Utility Station Wagon\",\n",
    "          17:\"3-Door Coupe\",\n",
    "          19:\"Utility Unknown Body\",\n",
    "          20:\"Minivan\",\n",
    "          21:\"Large Van – Includes Van-Based Buses\",\n",
    "          22:\"Step Van or Walk-In Van (GVWR ≤ 10,000 lbs)\",\n",
    "          28:\"Other Van Type (Hi-Cube Van)\",\n",
    "          29:\"Unknown Van Type\",\n",
    "          30:\"Compact Pickup (GVWR, < 4,500 lbs)\",\n",
    "          31:\"Standard Pickup (4,500 lbs <= GVWR < 10,000 lbs)\",\n",
    "          32:\"Pickup with Slide-In Camper\",\n",
    "          33:\"Convertible Pickup\",\n",
    "          34:\"Light Pickup\",\n",
    "          39:\"Unknown (Pickup Style) Light Conventional Truck Type\",\n",
    "          40:\"Cab Chassis-Based (Includes Light Stake, Light Dump, Light Tow, Rescue Vehicles)\",\n",
    "          41:\"Truck-Based Panel\",\n",
    "          42:\"Light-Truck-Based Motorhome (Chassis Mounted)\",\n",
    "          45:\"Other Light Conventional Truck Type (Includes Stretched Suburban Limousine)\",\n",
    "          48:\"Unknown Light Truck Type (Since 2013)\",\n",
    "          49:\"Unknown Light-Vehicle Type (Automobile, Utility Vehicle, Van or Light Truck)\",\n",
    "          50:\"School Bus\",\n",
    "          51:\"Cross-Country/Intercity Bus (i.e., Greyhound)\",\n",
    "          52:\"Transit Bus (City Bus)\",\n",
    "          55:\"Van-Based Bus (GVWR > 10,000 lbs) (Since 2011)\",\n",
    "          58:\"Other Bus Type\",\n",
    "          59:\"Unknown Bus Type\",\n",
    "          60:\"Step Van (GVWR > 10,000 lbs.)\",\n",
    "          61:\"Single-Unit Straight Truck or Cab-Chassis (GVWR range 10,001 to 19,500 lbs) (Since 2011)\",\n",
    "          62:\"Single-Unit Straight Truck or Cab-Chassis (GVWR range 19,501 to 26,000 lbs) (Since 2011)\",\n",
    "          63:\"Single-Unit Straight Truck or Cab-Chassis (GVWR > 26,000 lbs) (Since 2011)\",\n",
    "          64:\"Single Unit Straight Truck or Cab-Chassis (GVWR Unknown) (Since 2011)\",\n",
    "          65:\"Medium/Heavy Truck-Based Motorhome\",\n",
    "          66:\"Truck/Tractor (Cab Only, or with Any Number of Trailing Units: Any Weight)\",\n",
    "          67:\"Medium/Heavy Pickup (GVWR > 10,000 lbs) (Since 2001)\",\n",
    "          72:\"Unknown if Single-Unit or Combination-Unit Heavy Truck (GVWR > 26,000 lbs)\",\n",
    "          73:\"Camper or Motorhome, Unknown Truck Type\",\n",
    "          78:\"Unknown Medium/Heavy Truck Type\",\n",
    "          79:\"Unknown Truck Type\",\n",
    "          80:\"Two Wheel Motorcycle (excluding motor scooters)\",\n",
    "          81:\"Moped or Motorized Bicycle\",\n",
    "          82:\"Three-Wheel Motorcycle (2 Rear Wheels)\",\n",
    "          83:\"Off-Road Motorcycle\",\n",
    "          84:\"Motor Scooter\",\n",
    "          85:\"Unenclosed 3-Wheel Motorcycle / Unenclosed Autocycle (1 Rear Wheel)\",\n",
    "          86:\"Enclosed 3-Wheel Motorcycle / Enclosed Autocycle (1 Rear Wheel)\",\n",
    "          87:\"Unknown Three Wheel Motorcycle Type\",\n",
    "          88:\"Other Motored Cycle Type (Mini-Bikes, Pocket Motorcycles, 'Pocket Bikes')\",\n",
    "          89:\"Unknown Motored Cycle Type\",\n",
    "          90:\"ATV (All-Terrain Vehicle; Includes 3 or 4 Wheels)\",\n",
    "          91:\"Snowmobile\",\n",
    "          92:\"Farm Equipment Other Than Trucks\",\n",
    "          93:\"Construction Equipment Other Than Trucks (Includes Graders)\",\n",
    "          94:\"Low Speed Vehicle (LSV)/Neighborhood Electric Vehicle (NEV) (Since 2011)\",\n",
    "          95:\"Golf Cart (Since 2012)\",\n",
    "          96:\"Recreational Off-Highway Vehicle\",\n",
    "          97:\"Other Vehicle Type (Includes Go-Cart, Fork-Lift, City Street Sweeper, Dune/Swamp Buggy)\",\n",
    "          98:\"Not Reported\",\n",
    "          99:\"Unknown Body Type\"}  \n",
    "FARS=FARS.replace({\"BODY_TYP\": Bodytype})  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare major factors between fatal crash and injury-only crash."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First, let's take a look at light condition between Fatal and Injury-only Crash.\n",
    "From the visualization, the majority of accidents in both types of accidents happen under the condition of 'Daylight'. However, more percentage of fatal accidents happened in 'Dark-Lighted', 'Dark-Not lighted' compared to injury-only accidents. \n",
    "So light condition is an important factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_LG=FARS.groupby(['LGT_COND'])['ST_CASE'].nunique().reset_index().rename(columns={'ST_CASE':'COUNT'})\n",
    "FARS_LG=FARS_LG.set_index(['LGT_COND'])\n",
    "FARS_LG[\"%\"] = FARS_LG.apply(lambda x:  100*x / x.sum())\n",
    "\n",
    "CRSS_LG=CRSS.groupby(['LGT_COND'])['CASENUM'].nunique().reset_index().rename(columns={'CASENUM':'COUNT'})\n",
    "CRSS_LG=CRSS_LG.set_index(['LGT_COND'])\n",
    "CRSS_LG[\"%\"] = CRSS_LG.apply(lambda x:  100*x / x.sum())\n",
    "\n",
    "FARS_LG_styler = FARS_LG.style.set_table_attributes(\"style='display:inline'\").set_caption('Fatal-accident')\n",
    "CRSS_LG_styler = CRSS_LG.style.set_table_attributes(\"style='display:inline'\").set_caption('Injury-Only accident')\n",
    "\n",
    "display_html(FARS_LG_styler._repr_html_()+CRSS_LG_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS.dropna(subset=['LGT_COND'],inplace = True)\n",
    "CRSS.dropna(subset=['LGT_COND'],inplace = True)\n",
    "FARS_sort = FARS.sort_values('LGT_COND',ascending=True)\n",
    "CRSS_sort = CRSS.sort_values('LGT_COND',ascending=True)\n",
    "f,ax=plt.subplots(1,2,figsize=(15,11))\n",
    "sns.set(font_scale=1)\n",
    "rc={'font.size': 12, 'axes.labelsize': 12, \n",
    "    'axes.titlesize': 15, 'xtick.labelsize':12, 'ytick.labelsize': 12}\n",
    "sns.set_context(rc=rc)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "sns.histplot(FARS_sort[\"LGT_COND\"],ax=ax[0])\n",
    "ax[0].set_title('Distribution of Light Condition - Fatal Accident')\n",
    "plt.setp(ax[0].get_xticklabels(), rotation=90)\n",
    "ax[0].ticklabel_format(style='plain', axis='y', scilimits=(0,0),useOffset=False)\n",
    "\n",
    "\n",
    "sns.histplot(CRSS_sort[\"LGT_COND\"],ax=ax[1])\n",
    "ax[1].set_title('Distribution of Light Condition - Injury-Only')\n",
    "plt.setp(ax[1].get_xticklabels(), rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Next, let's take a look and see if single car accident/multi-car accident is another factor leading to fatal accidents.\n",
    "So from the chart below, it is surprisingly that among fatal accidents, 48% of fatal accidents are single vehicle accidents while only 28% of injury-only are single-vehicle accidents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import display_html \n",
    "FARS_ve=FARS.groupby(['VE_TOTAL'])['ST_CASE'].nunique().reset_index().rename(columns={'ST_CASE':'COUNT'})\n",
    "FARS_ve=FARS_ve.set_index(['VE_TOTAL'])\n",
    "FARS_ve[\"%\"] = FARS_ve.apply(lambda x:  100*x / x.sum())\n",
    "\n",
    "CRSS_ve=CRSS.groupby(['VE_TOTAL'])['CASENUM'].nunique().reset_index().rename(columns={'CASENUM':'COUNT'})\n",
    "CRSS_ve=CRSS_ve.set_index(['VE_TOTAL'])\n",
    "CRSS_ve[\"%\"] = CRSS_ve.apply(lambda x:  100*x / x.sum())\n",
    "\n",
    "FARS_ve_styler = FARS_ve.style.set_table_attributes(\"style='display:inline'\").set_caption('Fatal-accident')\n",
    "CRSS_ve_styler = CRSS_ve.style.set_table_attributes(\"style='display:inline'\").set_caption('Injury-Only accident')\n",
    "\n",
    "display_html(FARS_ve_styler._repr_html_()+CRSS_ve_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_ve=FARS_ve.reset_index()\n",
    "CRSS_ve=CRSS_ve.reset_index()\n",
    "\n",
    "f,ax=plt.subplots(1,2,figsize=(15,10))\n",
    "sns.set(font_scale=1)\n",
    "rc={'font.size': 10, 'axes.labelsize': 12, \n",
    "    'axes.titlesize': 15, 'xtick.labelsize':10, 'ytick.labelsize': 10}\n",
    "sns.set_context(rc=rc)\n",
    "sns.set_style(\"white\")\n",
    "sns.barplot(x='VE_TOTAL',y='COUNT',ax=ax[0],data=FARS_ve)\n",
    "#sns.histplot(FARS[\"VE_TOTAL\"],ax=ax[0],binwidth=1)\n",
    "ax[0].set_title('Distribution of Total Vehicles Involved - Fatal Accident')\n",
    "ax[0].set(xlim=(0,8))\n",
    "ax[0].ticklabel_format(style='plain', axis='y', scilimits=(0,0),useOffset=False)\n",
    "\n",
    "sns.barplot(x='VE_TOTAL',y='COUNT',ax=ax[1],data=CRSS_ve)\n",
    "#sns.histplot(CRSS[\"VE_TOTAL\"],ax=ax[1],binwidth=1)\n",
    "ax[1].set_title('Distribution of Total Vehicles Involved - Injury-Only')\n",
    "ax[1].set(xlim=(0,8))\n",
    "    \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As alcohol involvement is a critical factor for accident, let's compare it.\n",
    "It's good that we see the majority in both fatal and injury-only accidents are non-alcohol involved.\n",
    "However, if we compare fatal with injury-only, we could see that 37.42% of fatal accidents has at least 1 drunk driver involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import display_html \n",
    "FARS_al=FARS.groupby(['DRUNK_DR'])['ST_CASE'].nunique().reset_index().rename(columns={'ST_CASE':'COUNT'})\n",
    "FARS_al=FARS_al.set_index(['DRUNK_DR'])\n",
    "FARS_al[\"%\"] = FARS_al.apply(lambda x:  100*x / x.sum())\n",
    "\n",
    "CRSS_al=CRSS.groupby(['ALCOHOL'])['CASENUM'].nunique().reset_index().rename(columns={'CASENUM':'COUNT'})\n",
    "CRSS_al=CRSS_al.set_index(['ALCOHOL'])\n",
    "CRSS_al[\"%\"] = CRSS_al.apply(lambda x:  100*x / x.sum())\n",
    "\n",
    "FARS_al_styler = FARS_al.style.set_table_attributes(\"style='display:inline'\").set_caption('Fatal-accident')\n",
    "CRSS_al_styler = CRSS_al.style.set_table_attributes(\"style='display:inline'\").set_caption('Injury-Only accident')\n",
    "\n",
    "display_html(FARS_al_styler._repr_html_()+CRSS_al_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_al=FARS_al.reset_index()\n",
    "CRSS_al=CRSS_al.reset_index()\n",
    "\n",
    "f,ax=plt.subplots(1,2,figsize=(15,10))\n",
    "sns.set(font_scale=1)\n",
    "rc={'font.size': 10, 'axes.labelsize': 12, \n",
    "    'axes.titlesize': 15, 'xtick.labelsize':10, 'ytick.labelsize': 10}\n",
    "sns.set_context(rc=rc)\n",
    "sns.set_style(\"white\")\n",
    "sns.barplot(x='DRUNK_DR',y='COUNT',ax=ax[0],data=FARS_al)\n",
    "#sns.histplot(FARS[\"DRUNK_DR\"],ax=ax[0],binwidth=1)\n",
    "ax[0].set_title('Distribution of Drunk Driver Involved - Fatal Accident')\n",
    "ax[0].ticklabel_format(style='plain', axis='y', scilimits=(0,0),useOffset=False)\n",
    "\n",
    "\n",
    "sns.barplot(x='ALCOHOL',y='COUNT',ax=ax[1],data=CRSS_al)\n",
    "#sns.histplot(CRSS[\"ALCOHOL\"],ax=ax[1],binwidth=2)\n",
    "ax[1].set_title('Distribution of Alcohol Involved - Injury-Only')\n",
    "plt.setp(ax[1].get_xticklabels(), rotation=90)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now, let's see if weather will lead to more fatal accidents.\n",
    "From the chart, we could see that the weather distribution is very identical between two type of accidents.\n",
    "Thus, we may know that weather isn't a key factor that cause fatal accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_w=FARS.groupby(['WEATHER'])['ST_CASE'].nunique().reset_index().rename(columns={'ST_CASE':'COUNT'})\n",
    "FARS_w=FARS_w.set_index(['WEATHER'])\n",
    "FARS_w[\"%\"] = FARS_w.apply(lambda x:  100*x / x.sum())\n",
    "\n",
    "CRSS_w=CRSS.groupby(['WEATHER'])['CASENUM'].nunique().reset_index().rename(columns={'CASENUM':'COUNT'})\n",
    "CRSS_w=CRSS_w.set_index(['WEATHER'])\n",
    "CRSS_w[\"%\"] = CRSS_w.apply(lambda x:  100*x / x.sum())\n",
    "\n",
    "FARS_w_styler = FARS_w.style.set_table_attributes(\"style='display:inline'\").set_caption('Fatal-accident')\n",
    "CRSS_w_styler = CRSS_w.style.set_table_attributes(\"style='display:inline'\").set_caption('Injury-Only accident')\n",
    "\n",
    "display_html(FARS_w_styler._repr_html_()+CRSS_w_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FARS_sort = FARS.sort_values('WEATHER',ascending=True)\n",
    "#CRSS_sort = CRSS.sort_values('WEATHER',ascending=True)\n",
    "FARS_w=FARS_w.reset_index()\n",
    "CRSS_w=CRSS_w.reset_index()\n",
    "\n",
    "f,ax=plt.subplots(1,2,figsize=(15,10))\n",
    "sns.set(font_scale=1)\n",
    "rc={'font.size': 10, 'axes.labelsize': 12, \n",
    "    'axes.titlesize': 15, 'xtick.labelsize':8, 'ytick.labelsize': 8}\n",
    "sns.set_context(rc=rc)\n",
    "sns.set_style(\"white\")\n",
    "#FARS.dropna(subset=['WEATHER'],inplace = True)\n",
    "#CRSS.dropna(subset=['WEATHER'],inplace = True)\n",
    "sns.barplot(x='WEATHER',y='COUNT',ax=ax[0],data=FARS_w)\n",
    "#sns.histplot(FARS_sort[\"WEATHER\"],ax=ax[0])\n",
    "ax[0].set_title('Distribution of Weather - Fatal Accident')\n",
    "plt.setp(ax[0].get_xticklabels(), rotation=90)\n",
    "\n",
    "sns.barplot(x='WEATHER',y='COUNT',ax=ax[1],data=CRSS_w)\n",
    "#sns.histplot(CRSS_sort[\"WEATHER\"],ax=ax[1])\n",
    "ax[1].set_title('Distribution of Weather - Injury-Only')\n",
    "plt.setp(ax[1].get_xticklabels(), rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Next, we will take a look at how the collion manner different between both accidents.\n",
    "What we have noticed that 48.5% of fatal accidents are 'Not Collision with Motor Vehicle in Transport' which aligns with what we have seen in the factor or single-vehicle/muti-vehicle.\n",
    "Besides, we find out that more (14.00%) fatal accidents has front-to-front manner of collision compared to 3.7% injury-only accident. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_col=FARS.groupby(['MAN_COLL_x'])['ST_CASE'].nunique().reset_index().rename(columns={'ST_CASE':'COUNT'})\n",
    "FARS_col=FARS_col.set_index(['MAN_COLL_x'])\n",
    "FARS_col[\"%\"] = FARS_col.apply(lambda x:  100*x / x.sum())\n",
    "\n",
    "CRSS_col=CRSS.groupby(['MAN_COLL_x'])['CASENUM'].nunique().reset_index().rename(columns={'CASENUM':'COUNT'})\n",
    "CRSS_col=CRSS_col.set_index(['MAN_COLL_x'])\n",
    "CRSS_col[\"%\"] = CRSS_col.apply(lambda x:  100*x / x.sum())\n",
    "\n",
    "FARS_col_styler = FARS_col.style.set_table_attributes(\"style='display:inline'\").set_caption('Fatal-accident')\n",
    "CRSS_col_styler = CRSS_col.style.set_table_attributes(\"style='display:inline'\").set_caption('Injury-Only accident')\n",
    "\n",
    "display_html(FARS_col_styler._repr_html_()+CRSS_col_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FARS_sort = FARS.sort_values('MAN_COLL_x',ascending=True)\n",
    "#CRSS_sort = CRSS.sort_values('MAN_COLL_x',ascending=True)\n",
    "FARS_col=FARS_col.reset_index()\n",
    "CRSS_col=CRSS_col.reset_index()\n",
    "\n",
    "f,ax=plt.subplots(1,2,figsize=(15,10))\n",
    "sns.set(font_scale=1)\n",
    "rc={'font.size': 10, 'axes.labelsize': 12, \n",
    "    'axes.titlesize': 15, 'xtick.labelsize':8, 'ytick.labelsize': 8}\n",
    "sns.set_context(rc=rc)\n",
    "sns.set_style(\"white\")\n",
    "#FARS.dropna(subset=['WEATHER'],inplace = True)\n",
    "#CRSS.dropna(subset=['WEATHER'],inplace = True)\n",
    "sns.barplot(x='MAN_COLL_x',y='COUNT',ax=ax[0],data=FARS_col)\n",
    "#sns.histplot(FARS_sort[\"MAN_COLL_x\"],ax=ax[0])\n",
    "ax[0].set_title('Distribution of Manner of Collision - Fatal Accident')\n",
    "plt.setp(ax[0].get_xticklabels(), rotation=90)\n",
    "ax[0].ticklabel_format(style='plain', axis='y', scilimits=(0,0),useOffset=False)\n",
    "\n",
    "sns.barplot(x='MAN_COLL_x',y='COUNT',ax=ax[1],data=CRSS_col)\n",
    "#sns.histplot(CRSS_sort[\"MAN_COLL_x\"],ax=ax[1])\n",
    "ax[1].set_title('Distribution of Manner of Collision - Injury-Only')\n",
    "plt.setp(ax[1].get_xticklabels(), rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We are curious to see the position of the crash relates to the trafficway.\n",
    "The Rel_road variable identifies the location of the crash as it relates to its position within or outside the trafficway.\n",
    "Combine this information with the manner of collision, we could get more sense of how and where the collison happened in a traffic way.\n",
    "\n",
    "When we compare both types of accidents, the majority happens 'On Roadway'.\n",
    "What differs is more (19.81%) fatal accidents happen 'On Roadside' compared to 7.41% of injury-only accident. This further validates that single-vehicle or vehicle that is not in collision with another vehicle is more common in fatal accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_rel=FARS.groupby(['REL_ROAD'])['ST_CASE'].nunique().reset_index().rename(columns={'ST_CASE':'COUNT'})\n",
    "FARS_rel=FARS_rel.set_index(['REL_ROAD'])\n",
    "FARS_rel[\"%\"] = FARS_rel.apply(lambda x:  100*x / x.sum())\n",
    "\n",
    "CRSS_rel=CRSS.groupby(['REL_ROAD'])['CASENUM'].nunique().reset_index().rename(columns={'CASENUM':'COUNT'})\n",
    "CRSS_rel=CRSS_rel.set_index(['REL_ROAD'])\n",
    "CRSS_rel[\"%\"] = CRSS_rel.apply(lambda x:  100*x / x.sum())\n",
    "\n",
    "FARS_rel_styler = FARS_rel.style.set_table_attributes(\"style='display:inline'\").set_caption('Fatal-accident')\n",
    "CRSS_rel_styler = CRSS_rel.style.set_table_attributes(\"style='display:inline'\").set_caption('Injury-Only accident')\n",
    "\n",
    "display_html(FARS_rel_styler._repr_html_()+CRSS_rel_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FARS.dropna(subset=['REL_ROAD'],inplace = True)\n",
    "#CRSS.dropna(subset=['REL_ROAD'],inplace = True)\n",
    "#FARS_sort = FARS.sort_values('REL_ROAD',ascending=True)\n",
    "#CRSS_sort = CRSS.sort_values('REL_ROAD',ascending=True)\n",
    "FARS_rel=FARS_rel.reset_index()\n",
    "CRSS_rel=CRSS_rel.reset_index()\n",
    "\n",
    "f,ax=plt.subplots(1,2,figsize=(15,10))\n",
    "sns.set(font_scale=1)\n",
    "rc={'font.size': 10, 'axes.labelsize': 12, \n",
    "    'axes.titlesize': 15, 'xtick.labelsize':8, 'ytick.labelsize': 8}\n",
    "sns.set_context(rc=rc)\n",
    "sns.set_style(\"white\")\n",
    "ax[0].ticklabel_format(style='plain', axis='y', scilimits=(0,0),useOffset=False)\n",
    "\n",
    "#FARS.dropna(subset=['WEATHER'],inplace = True)\n",
    "#CRSS.dropna(subset=['WEATHER'],inplace = True)\n",
    "\n",
    "sns.barplot(x='REL_ROAD',y='COUNT',ax=ax[0],data=FARS_rel)\n",
    "#sns.histplot(FARS_sort[\"REL_ROAD\"],ax=ax[0])\n",
    "ax[0].set_title('Distribution of Relationship to TrafficWay - Fatal Accident')\n",
    "plt.setp(ax[0].get_xticklabels(), rotation=90)\n",
    "\n",
    "sns.barplot(x='REL_ROAD',y='COUNT',ax=ax[1],data=CRSS_rel)\n",
    "#sns.histplot(CRSS_sort[\"REL_ROAD\"],ax=ax[1])\n",
    "ax[1].set_title('Distribution of Relationship to TrafficWay - Injury-Only')\n",
    "plt.setp(ax[1].get_xticklabels(), rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### According to WHO, accidents that involve hazardous material may lead to more fatal accidents.\n",
    "Our dataset sample doesn't include much data records which has hazardous material involvement. But by quick check, we still see difference between fatal accidents and injury-only accident. Although we can't conclude that this factor plays large part, but 0.28% of our fatal-accidents records is hazardous material involved, while only 0.05% of our injury-only accidents are hazardous material involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_haz=FARS.groupby(['HAZ_INV'])['ST_CASE'].nunique().reset_index().rename(columns={'ST_CASE':'COUNT'})\n",
    "FARS_haz=FARS_haz.set_index(['HAZ_INV'])\n",
    "FARS_haz[\"%\"] = FARS_haz.apply(lambda x:  100*x / x.sum())\n",
    "\n",
    "CRSS_haz=CRSS.groupby(['HAZ_INV'])['CASENUM'].nunique().reset_index().rename(columns={'CASENUM':'COUNT'})\n",
    "CRSS_haz=CRSS_haz.set_index(['HAZ_INV'])\n",
    "CRSS_haz[\"%\"] = CRSS_haz.apply(lambda x:  100*x / x.sum())\n",
    "\n",
    "FARS_haz_styler = FARS_haz.style.set_table_attributes(\"style='display:inline'\").set_caption('Fatal-accident')\n",
    "CRSS_haz_styler = CRSS_haz.style.set_table_attributes(\"style='display:inline'\").set_caption('Injury-Only accident')\n",
    "\n",
    "display_html(FARS_haz_styler._repr_html_()+CRSS_haz_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FARS.dropna(subset=['HAZ_INV'],inplace = True)\n",
    "#CRSS.dropna(subset=['HAZ_INV'],inplace = True)\n",
    "FARS_haz=FARS_haz.reset_index()\n",
    "CRSS_haz=CRSS_haz.reset_index()\n",
    "\n",
    "f,ax=plt.subplots(1,2,figsize=(15,10))\n",
    "sns.set(font_scale=1)\n",
    "rc={'font.size': 10, 'axes.labelsize': 12, \n",
    "    'axes.titlesize': 15, 'xtick.labelsize':8, 'ytick.labelsize': 8}\n",
    "sns.set_context(rc=rc)\n",
    "sns.set_style(\"white\")\n",
    "#FARS.dropna(subset=['WEATHER'],inplace = True)\n",
    "#CRSS.dropna(subset=['WEATHER'],inplace = True)\n",
    "ax[0].ticklabel_format(style='plain', axis='y', scilimits=(0,0),useOffset=False)\n",
    "\n",
    "sns.barplot(x='HAZ_INV',y='COUNT',ax=ax[0],data=FARS_haz)\n",
    "#sns.histplot(FARS[\"HAZ_INV\"],ax=ax[0])\n",
    "ax[0].set_title('Distribution of Hazordous Material Involvement - Fatal Accident')\n",
    "plt.setp(ax[0].get_xticklabels(), rotation=90)\n",
    "\n",
    "sns.barplot(x='HAZ_INV',y='COUNT',ax=ax[1],data=CRSS_haz)\n",
    "#sns.histplot(CRSS[\"HAZ_INV\"],ax=ax[1])\n",
    "ax[1].set_title('Distribution of Hazordous Material Involvement - Injury-Only')\n",
    "plt.setp(ax[1].get_xticklabels(), rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Another Important thing to check is whether a rollover is involved in an accident.\n",
    "It is clear that more rollover occur in fatal accidents which does make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_roll=FARS.groupby(['ROLLOVER'])['ST_CASE'].nunique().reset_index().rename(columns={'ST_CASE':'COUNT'})\n",
    "FARS_roll=FARS_roll.set_index(['ROLLOVER'])\n",
    "FARS_roll[\"%\"] = FARS_roll.apply(lambda x:  100*x / x.sum())\n",
    "\n",
    "CRSS_roll=CRSS.groupby(['ROLLOVER'])['CASENUM'].nunique().reset_index().rename(columns={'CASENUM':'COUNT'})\n",
    "CRSS_roll=CRSS_roll.set_index(['ROLLOVER'])\n",
    "CRSS_roll[\"%\"] = CRSS_roll.apply(lambda x:  100*x / x.sum())\n",
    "\n",
    "FARS_roll_styler = FARS_roll.style.set_table_attributes(\"style='display:inline'\").set_caption('Fatal-accident')\n",
    "CRSS_roll_styler = CRSS_roll.style.set_table_attributes(\"style='display:inline'\").set_caption('Injury-Only accident')\n",
    "\n",
    "display_html(FARS_roll_styler._repr_html_()+CRSS_roll_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FARS_sort = FARS.sort_values('ROLLOVER',ascending=True)\n",
    "#CRSS_sort = CRSS.sort_values('ROLLOVER',ascending=True)\n",
    "FARS_roll=FARS_roll.reset_index()\n",
    "CRSS_roll=CRSS_roll.reset_index()\n",
    "\n",
    "f,ax=plt.subplots(1,2,figsize=(15,10))\n",
    "sns.set(font_scale=1)\n",
    "rc={'font.size': 10, 'axes.labelsize': 12, \n",
    "    'axes.titlesize': 15, 'xtick.labelsize':8, 'ytick.labelsize': 8}\n",
    "sns.set_context(rc=rc)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "sns.barplot(x='ROLLOVER',y='COUNT',ax=ax[0],data=FARS_roll)\n",
    "#sns.histplot(FARS_sort[\"ROLLOVER\"],ax=ax[0])\n",
    "#sns.displot(FARS_sort,x=\"ROLLOVER\",ax=axes[0], hue=\"DR_DRINK\")\n",
    "ax[0].set_title('Distribution of Rollover - Fatal Accident')\n",
    "plt.setp(ax[0].get_xticklabels(), rotation=90)\n",
    "ax[0].ticklabel_format(style='plain', axis='y', scilimits=(0,0),useOffset=False)\n",
    "\n",
    "\n",
    "sns.barplot(x='ROLLOVER',y='COUNT',ax=ax[1],data=CRSS_roll)\n",
    "#sns.histplot(CRSS_sort[\"ROLLOVER\"],ax=ax[1])\n",
    "#sns.displot(CRSS_sort,x=\"ROLLOVER\",ax=axes[1], hue=\"ALCOHOL\")\n",
    "ax[1].set_title('Distribution of Rollover - Injury-Only')\n",
    "plt.setp(ax[1].get_xticklabels(), rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One last factor to compare is if fire occured in an accident in a vehicle.\n",
    "It is obvious that more fatal accidents have fire occurrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_fire=FARS.groupby(['FIRE_EXP'])['ST_CASE'].nunique().reset_index().rename(columns={'ST_CASE':'COUNT'})\n",
    "FARS_fire=FARS_fire.set_index(['FIRE_EXP'])\n",
    "FARS_fire[\"%\"] = FARS_fire.apply(lambda x:  100*x / x.sum())\n",
    "\n",
    "CRSS_fire=CRSS.groupby(['FIRE_EXP'])['CASENUM'].nunique().reset_index().rename(columns={'CASENUM':'COUNT'})\n",
    "CRSS_fire=CRSS_fire.set_index(['FIRE_EXP'])\n",
    "CRSS_fire[\"%\"] = CRSS_fire.apply(lambda x:  100*x / x.sum())\n",
    "\n",
    "FARS_fire_styler = FARS_fire.style.set_table_attributes(\"style='display:inline'\").set_caption('Fatal-accident')\n",
    "CRSS_fire_styler = CRSS_fire.style.set_table_attributes(\"style='display:inline'\").set_caption('Injury-Only accident')\n",
    "\n",
    "display_html(FARS_fire_styler._repr_html_()+CRSS_fire_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_fire=FARS_fire.reset_index()\n",
    "CRSS_fire=CRSS_fire.reset_index()\n",
    "\n",
    "f,ax=plt.subplots(1,2,figsize=(15,10))\n",
    "sns.set(font_scale=1)\n",
    "rc={'font.size': 10, 'axes.labelsize': 12, \n",
    "    'axes.titlesize': 15, 'xtick.labelsize':8, 'ytick.labelsize': 8}\n",
    "sns.set_context(rc=rc)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "sns.barplot(x='FIRE_EXP',y='COUNT',ax=ax[0],data=FARS_fire)\n",
    "#sns.histplot(FARS[\"FIRE_EXP\"],ax=ax[0])\n",
    "#sns.displot(FARS_sort,x=\"ROLLOVER\",ax=axes[0], hue=\"DR_DRINK\")\n",
    "ax[0].set_title('Distribution of Fire Occurrence - Fatal Accident')\n",
    "plt.setp(ax[0].get_xticklabels(), rotation=90)\n",
    "ax[0].ticklabel_format(style='plain', axis='y', scilimits=(0,0),useOffset=False)\n",
    "\n",
    "sns.barplot(x='FIRE_EXP',y='COUNT',ax=ax[1],data=CRSS_fire)\n",
    "#sns.histplot(CRSS[\"FIRE_EXP\"],ax=ax[1])\n",
    "#sns.displot(CRSS_sort,x=\"ROLLOVER\",ax=axes[1], hue=\"ALCOHOL\")\n",
    "ax[1].set_title('Distribution of Fire Occurrence - Injury-Only')\n",
    "plt.setp(ax[1].get_xticklabels(), rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we will focus more on fatal-crash and find if there's any patterns among this type of accident."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's first take a look at hours that most fatal crash accident happen.\n",
    "From the combo chart below, we are able to find out that fatal accidents also follow peak hours.\n",
    "While the bars are showing number of fatals by hours which are very identical among hours.\n",
    "However, we could notice that drunk driver involved fatal accidents increases in the evening and reaches the top at 2 o'clock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_hour = FARS[FARS['HOUR_x']<99]\n",
    "FARS_hour2=FARS_hour.groupby(['HOUR_x','DR_DRINK'])['ST_CASE'].nunique().reset_index().rename(columns={'ST_CASE':'COUNT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(18,10))\n",
    "color = 'tab:green'\n",
    "#bar plot creation\n",
    "ax1.set_title('Number of Fatals by Hour', fontsize=16)\n",
    "ax1.set_xlabel('HOUR_x', fontsize=16)\n",
    "ax1.set_ylabel('Number of Fatals', fontsize=16,color='red')\n",
    "ax1 = sns.barplot(data=FARS_hour, x='HOUR_x',y='FATALS',palette='Reds')\n",
    "ax1.tick_params(axis='y')\n",
    "ax1.grid(False)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "#color = 'tab:red'\n",
    "#line plot creation\n",
    "ax2.set_ylabel('Number of Accidents', fontsize=16,color='Orange')\n",
    "ax2 = sns.lineplot(data=FARS_hour2, x='HOUR_x',y='COUNT',hue='DR_DRINK',style='DR_DRINK',palette=\"Set2\")\n",
    "ax2.tick_params(axis='y')\n",
    "ax2.grid(False)\n",
    "#show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now, let's look at the relationship between number of vehicle involves vs damage level of vehicles.\n",
    "From the heatmap, we could see that single vehicle accidents have most cases in 'disabling damage' for fatal accidents which align with our findings in previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_dam_ve=FARS.groupby(['DEFORMED','VE_TOTAL'])['ST_CASE'].nunique().reset_index().rename(columns={'ST_CASE':'COUNT'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,15))         # Sample figsize in inches\n",
    "\n",
    "heatmap_dam_ve_2 = pd.pivot_table(data=heatmap_dam_ve,\n",
    "                    index='DEFORMED',\n",
    "                    values='COUNT',\n",
    "                    columns='VE_TOTAL')\n",
    "sns.heatmap(heatmap_dam_ve_2,cmap='coolwarm',annot=True,fmt=\".1f\",annot_kws={'size':12},linewidths=.5, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's see if speeding is directly related to fatal accident.\n",
    "Speed_rel records whether the driver's speed was related to the crash as indicated by law enforcement.\n",
    "\n",
    "So we can see that 21.31% of fatal accidents is directly related to speeding. Among which, 6.9% exceeded speed limit and 7.6% is too fast for conditions. This implies that speeding is one of the major reason leads to fatal accident. Although we have educated drivers not to exceed speed limit and drive not too fast, there are still lots of space to improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Speed_rel={0:\"No\", 2:\"Yes, Racing\", 3:\"Yes, Exceeded Speed Limit\", \n",
    "         4:\"Yes, Too Fast for Conditions\", 5:\"Yes, Specifics Unknown\",\n",
    "           8:\"No Driver Present/Unknown if Driver Present\",\n",
    "     9:\"Reported as Unknown\"\n",
    "        }\n",
    "\n",
    "FARS=FARS.replace({\"SPEEDREL\": Speed_rel})\n",
    "\n",
    "\n",
    "\n",
    "conditions = [\n",
    "    (FARS['SPEEDREL'] == 'Yes, Racing') | (FARS['SPEEDREL'] == 'Yes, Exceeded Speed Limit')|(FARS['SPEEDREL'] == 'Yes, Too Fast for Conditions')\n",
    "    |(FARS['SPEEDREL'] == 'Yes, Specifics Unknown')\n",
    "    ,(FARS['SPEEDREL'] == 'No')| (FARS['SPEEDREL'] == 'No Driver Present/Unknown if Driver Present'),\n",
    " (FARS['SPEEDREL'] == 'Reported as Unknown')]\n",
    "choices = ['Yes, speed related crash', 'No','Unknown']\n",
    "FARS['SPEEDREL_BIN'] = np.select(conditions, choices, default='Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_sp=FARS.groupby(['SPEEDREL'])['ST_CASE'].nunique().reset_index().rename(columns={'ST_CASE':'COUNT'})\n",
    "FARS_sp=FARS_sp.set_index(['SPEEDREL'])\n",
    "FARS_sp[\"%\"] = FARS_sp.apply(lambda x:  100*x / x.sum())\n",
    "\n",
    "CRSS_sp=CRSS.groupby(['SPEEDREL'])['CASENUM'].nunique().reset_index().rename(columns={'CASENUM':'COUNT'})\n",
    "CRSS_sp=CRSS_sp.set_index(['SPEEDREL'])\n",
    "CRSS_sp[\"%\"] = CRSS_sp.apply(lambda x:  100*x / x.sum())\n",
    "\n",
    "FARS_sp_styler = FARS_sp.style.set_table_attributes(\"style='display:inline'\").set_caption('Fatal-accident')\n",
    "CRSS_sp_styler = CRSS_sp.style.set_table_attributes(\"style='display:inline'\").set_caption('Injury-Only accident')\n",
    "\n",
    "display_html(FARS_sp_styler._repr_html_()+CRSS_sp_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We already know that speed is critical factor, and let's combine it with the level of damage of vehicles.\n",
    "From the box plot, we can confirm that the level of damage is more severe as travelling speed increases.\n",
    "We have further categorize the accident based on speed_rel and the color grey marks the accident which is speed related according to law enforcement. \n",
    "We could see that in the most severe damage 'Disabling damage', the overall travelling speed is higher compared to the other level of damage. And at the same time, the 'speed related crash' has the highest median speed at 70 mph.\n",
    "From this plot, we could learn that speed is also directly related to vehicle level of damage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fars_dedup=FARS.drop_duplicates(['ST_CASE','DEFORMED','SPEEDREL_BIN','TRAV_SP'])[['ST_CASE','DEFORMED','SPEEDREL_BIN','TRAV_SP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_Trv_sp = Fars_dedup[Fars_dedup['TRAV_SP']<997]\n",
    "FARS_Trv_sp = FARS_Trv_sp.sort_values('SPEEDREL_BIN',ascending=True)\n",
    "plt.figure(figsize=(15,8))\n",
    "ax=sns.boxplot(x = 'DEFORMED', y = 'TRAV_SP', hue=\"SPEEDREL_BIN\", data = FARS_Trv_sp,linewidth=2,fliersize=5,palette=\"Set2\") \n",
    "_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "sns.set(font_scale =1)\n",
    "ax.set(ylim=(0, 200))\n",
    "ax.set_title('Travel Speed by Damage Level',fontsize=18)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "#Let's show the median values in the plot.\n",
    "m1 = FARS_Trv_sp.groupby(['DEFORMED',\"SPEEDREL_BIN\"])['TRAV_SP'].median().values\n",
    "mL1 = [str(np.round(s, 2)) for s in m1]\n",
    "\n",
    "\n",
    "ind = 0\n",
    "for tick in range(len(ax.get_xticklabels())):\n",
    "    ax.text(tick, m1[ind+1]+m1[ind+1]*0.1, mL1[ind+1],  horizontalalignment='center', size='medium', color='blue', weight='bold')\n",
    "    ax.text(tick+0.25, m1[ind+2]+m1[ind+2]*0.1, mL1[ind+2],  horizontalalignment='center', size='medium', color='blue', weight='bold')\n",
    "    ax.text(tick-0.25, m1[ind]+m1[ind]*0.1, mL1[ind], horizontalalignment='center', size='medium',color='blue', weight='bold')\n",
    "    ind += 3 \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's take a further look and see if surface type and surface conditions plays a role in fatal accident.\n",
    "From the heatmap below, we could see that the majority of accidents occur on 'Blacktop, Bituminous, or Saphalt' when it is 'dry', the other surface condition that has slightly more fatal accidents is 'wet'. But this is mostly due to these two conditions are more likely to occur among all seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_surface=FARS.groupby(['VPAVETYP','VSURCOND'])['ST_CASE'].nunique().reset_index().rename(columns={'ST_CASE':'COUNT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,15))         # Sample figsize in inches\n",
    "\n",
    "heatmap_surface_2 = pd.pivot_table(data=heatmap_surface,\n",
    "                    index='VPAVETYP',\n",
    "                    values='COUNT',\n",
    "                    columns='VSURCOND')\n",
    "sns.heatmap(heatmap_surface_2,cmap='flare',annot=True,fmt=\".1f\",annot_kws={'size':12},linewidths=.5, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, let's take a look at the body type, make in fatal accidents and combine the level of damage. \n",
    "So we can see from the Sunburst plot, the body type that has most accidents is 4-door sedan,compact utility, light pickup, two wheel motorcycle and truck. The top five vehicle make are Toyota, Chevrolet,Ford, Harley-Davidson, and Honda.\n",
    "It is likely because the majority of vehicles purchased by consumers are these brands and body type, but what worths note is that two wheel motorcycle tends to have higher fatal accident rate if compared the ownership of other body types of vehicles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_VEHICLE=FARS.groupby(['BODY_TYP'])['ST_CASE'].nunique().reset_index().rename(columns={'ST_CASE':'COUNT'})\n",
    "FARS_VEHICLE_sort =FARS_VEHICLE.sort_values('COUNT',ascending=False)\n",
    "FARS_VEHICLE_TOP20=FARS_VEHICLE_sort.head(20)\n",
    "FARS_VEHICLE_TOP20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,15))  \n",
    "sns.barplot(x = 'COUNT', y = 'BODY_TYP',data = FARS_VEHICLE_TOP20,\n",
    "             color = 'b', edgecolor = 'w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_VEHICLE_m_t=FARS.groupby(['BODY_TYP','MAKE','DEFORMED'])['ST_CASE'].nunique().reset_index().rename(columns={'ST_CASE':'COUNT'})\n",
    "FARS_VEHICLE_m_t_sort =FARS_VEHICLE_m_t.sort_values('COUNT',ascending=False)\n",
    "FARS_VEHICLE_m_t_sort_TOP30=FARS_VEHICLE_m_t_sort.head(30)\n",
    "FARS_VEHICLE_m_t_sort_TOP30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px \n",
    "fig = px.sunburst(FARS_VEHICLE_m_t_sort_TOP30, path=['BODY_TYP', 'MAKE'],  \n",
    "                  values='COUNT',color='COUNT') \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's take a look at cities with high cyclists involved fatal accidents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, we would like to see the top cities with more fatal accidents involving bike. However, after checking the number of accidents in these top 10 cities with most fatal accidents, we find out the number of accident is just too low to be analyzed as a sample which will not be able to be representative. Thus, we choose not to report this portion as an analysis result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cities['City'] = top_cities['City'].str.upper() \n",
    "top_cities['State[c]'] = top_cities['State[c]'].str.upper() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS['Bike_IND'] = np.where((FARS['PBPTYPE']==6)|(FARS['PBPTYPE']==7), \"Yes\", \"No\")\n",
    "\n",
    "FARS_bk=FARS.groupby(['Bike_IND','State Name','City Name'])['ST_CASE'].nunique().reset_index().rename(columns={'ST_CASE':'COUNT'})\n",
    "FARS_bk_inv=FARS_bk[FARS_bk['Bike_IND']=='Yes']\n",
    "FARS_bk_inv.drop(['Bike_IND'],axis=1,inplace=True)\n",
    "FARS_bk_inv.sort_values('COUNT',ascending=False).head(10)\n",
    "FARS_bk_inv=FARS_bk_inv.set_index(['State Name','City Name'])\n",
    "\n",
    "FARS_bk_inv[\"%\"] = FARS_bk_inv.apply(lambda x:  100*x / x.sum())\n",
    "FARS_bk_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_bk_inv=FARS_bk_inv.reset_index()\n",
    "FARS_bk_TOP10=FARS_bk_inv.sort_values('%',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_bk_TOP10_Popu=pd.merge(FARS_bk_TOP10, top_cities[['City','State[c]','2010Census','2016 land area','2016 population density']],  how='left', left_on=['City Name','State Name'], right_on = ['City','State[c]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_bk_TOP10_Popu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_only=FARS[FARS['Bike_IND']=='Yes']\n",
    "PB_Popu=pd.merge(bike_only, top_cities[['City','State[c]','2016 land area','2010Census','2016 population density']],  how='left', left_on=['City Name','State Name'], right_on = ['City','State[c]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PB_Popu_6state=PB_Popu[PB_Popu['State Name'].isin(['CALIFORNIA', 'ARIZONA','TEXAS','NEW YORK','ILLINOIS','FLORIDA'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PB_Popu_10cities=PB_Popu_6state[PB_Popu_6state['City Name'].isin(['LOS ANGELES','PHOENIX','HOUSTON','NEW YORK CITY','SACRAMENTO','STOCKTON','CHICAGO','JACKSONVILLE','NEW YORK','SAN JOSE'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bike_loc={1:\"At Intersection\", 2:\"Intersection-Related\", \n",
    "         3:\"Not At Intersection\", 4:\"Non-Trafficway Location\",\n",
    "           7:\"Not a Cyclist\",\n",
    "     9:\"Unknown/Insufficient Information\"\n",
    "        }\n",
    "\n",
    "FARS=FARS.replace({\"BIKELOC\": Bike_loc})\n",
    "\n",
    "\n",
    "Bike_pos={1:\"Travel Lane\", 2:\"Bicycle Lane/Paved Shoulder/Parking Lane\", \n",
    "         3:\"Sidewalk/Crosswalk/Driveway Access\", 4:\"Shared-Use Path\",\n",
    "          5:\"Non-Trafficway – Driveway\",6:\"Non-Trafficway – Parking Lot/Other\",\n",
    "           7:\"Not a Cyclist\",8:\"Other\",\n",
    "     9:\"Unknown\"\n",
    "        }\n",
    "\n",
    "\n",
    "PB_Popu_10cities=PB_Popu_10cities.replace({\"BIKELOC\": Bike_loc})\n",
    "PB_Popu_10cities=PB_Popu_10cities.replace({\"BIKEPOS\": Bike_pos})\n",
    "\n",
    "PB_BIKE=PB_Popu_10cities.groupby(['City Name','BIKEPOS','BIKELOC'])['ST_CASE'].nunique().reset_index().rename(columns={'ST_CASE':'COUNT'})\n",
    "PB_BIKE_SORT =PB_BIKE.sort_values('COUNT',ascending=False)\n",
    "PB_BIKE_SORT.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at all the records in the FARS data on a map to have an idea how they are distributed across the country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Folium Map of Top ten cities and add different attributes to the map such as Bike Stations, Accidents, Hospitals...\n",
    "m = folium.Map(location=[40, -96], zoom_start=4.4,prefer_canvas=True)\n",
    "\n",
    "for i in range(len(FARS)): #Top Cities\n",
    "    folium.Circle(location=[FARS['LATITUDE'][i], FARS['LONGITUD'][i]],\n",
    "      popup='name',\n",
    "      radius=15,\n",
    "      color='purple',\n",
    "      fill=True,\n",
    "      fill_color='purple'\n",
    "   ).add_to(m)\n",
    "    \n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As seen above, the number of accidents is time consuming and overwhelming that is why we need to filter the data to focus exclusively on accidents on the top cities and top ten cities in the country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relying on our functions previously defined we can filter the FARS and hospitals data set to get the top cities data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating filtered dataframes with FARS and Hospital data for topcities only\n",
    "FARS_Top_Cities = filter_top_cities(FARS)\n",
    "FARS_TopTen_Cities = filter_topten_cities(FARS)\n",
    "Hospitals_Top_Cities = filter_top_cities(hospitals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we are visualizing where and how it looks the FARS and Hospital data across the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Folium Map of Top ten cities and add different attributes to the map such as Bike Stations, Accidents, Hospitals...\n",
    "m = folium.Map(location=[40, -96], zoom_start=4.4,prefer_canvas=True)\n",
    "\n",
    "for i in range(len(top_cities)): #Top Cities\n",
    "    folium.Circle(location=[top_cities['Lat'][i], top_cities['Lon'][i]],\n",
    "      popup='name',\n",
    "      radius=15,\n",
    "      color='blue',\n",
    "      fill=True,\n",
    "      fill_color='blue'\n",
    "   ).add_to(m)\n",
    "    \n",
    "for i in range(len(FARS_Top_Cities)): #Crashes Top Cities\n",
    "    folium.Circle(location=[FARS_Top_Cities['LATITUDE'][i], FARS_Top_Cities['LONGITUD'][i]],\n",
    "      popup='name',\n",
    "      radius=80,\n",
    "      color='red',\n",
    "      fill=True,\n",
    "      fill_color='red'\n",
    "   ).add_to(m)    \n",
    "    \n",
    "for i in range(len(FARS_TopTen_Cities)): #Crashes Top Ten Cities\n",
    "    folium.Circle(location=[FARS_TopTen_Cities['LATITUDE'][i], FARS_TopTen_Cities['LONGITUD'][i]],\n",
    "      popup='name',\n",
    "      radius=150,\n",
    "      color='yellow',\n",
    "      fill=True,\n",
    "      fill_color='yellow'\n",
    "   ).add_to(m)   \n",
    "    \n",
    "# for i in range(len(crash_boston_cyclist_df)): #Crash invovled cyclist\n",
    "#     folium.Circle(location=[crash_boston_cyclist_df['latitude'][i], crash_boston_cyclist_df['longitud'][i]],\n",
    "#       popup='name',\n",
    "#       radius=500,\n",
    "#       color='yellow',\n",
    "#       fill=True,\n",
    "#       fill_color='yellow'\n",
    "#    ).add_to(m)   \n",
    "    \n",
    "for i in range(len(Hospitals_Top_Cities)): #Hospital Location\n",
    "    folium.Circle(location=[Hospitals_Top_Cities['LATITUDE'][i], Hospitals_Top_Cities['LONGITUDE'][i]],\n",
    "      popup='name',\n",
    "      radius=50,\n",
    "      color='green',\n",
    "      fill=True,\n",
    "      fill_color='green'\n",
    "   ).add_to(m) \n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given the fact that population and number of hospitals vary from city to city we want to normalize the data by calculating the fatal accidents and hospitals per 100,000 people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate FATAL Accidents per capita\n",
    "df = FARS_Top_Cities.groupby(['Top_City', 'Pop', 'Rank']).agg({'Rank': ['count', 'mean'],\n",
    "                                            'Pop': ['mean']})\n",
    "df.columns = df.columns.map('_'.join)\n",
    "df['FARS_PerCapita'] = round((df['Rank_count']/df['Pop_mean'])*100000,2)\n",
    "df.sort_values(by=['FARS_PerCapita'],ascending=False, inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df['pop'] = df.apply(lambda row: human_format(row['Pop_mean']), axis=1) #Apply human_format function\n",
    "\n",
    "# Calculate Hospitals Per Capita\n",
    "h = Hospitals_Top_Cities.groupby(['Top_City', 'Pop', 'Rank']).agg({'Rank': ['count', 'mean'],\n",
    "                                            'Pop': ['mean']})\n",
    "h.columns = h.columns.map('_'.join)\n",
    "h['Hospitals_PerCapita'] = round((h['Rank_count']/h['Pop_mean'])*100000,2)\n",
    "h.sort_values(by=['Hospitals_PerCapita'],ascending=False, inplace=True)\n",
    "h.reset_index(inplace=True)\n",
    "h\n",
    "\n",
    "perCapita = pd.merge(df, h,how=\"left\", on=[\"Top_City\", \"Pop\"], suffixes=('', '_y'))\n",
    "perCapita.drop(perCapita.filter(regex='_y$').columns.tolist(),axis=1, inplace=True)\n",
    "perCapita\n",
    "\n",
    "\n",
    "#indexes for fatal and nonfatal cities to be used for filtering\n",
    "fatal_cities = df['Top_City'][0:10]\n",
    "non_fatal_cities = df['Top_City'][-10:]\n",
    "fatal_ranks = df['Rank_mean'][0:10]\n",
    "non_fatal_ranks = df['Rank_mean'][-10:]\n",
    "fatal_perCapita = df['FARS_PerCapita'][0:10]\n",
    "non_fatal_perCapita = df['FARS_PerCapita'][-10:]\n",
    "\n",
    "# Additional df to be used later for filtering\n",
    "df1 = pd.DataFrame({'Top_City': fatal_cities, 'Rank_mean': fatal_ranks, 'FARS_PerCapita': fatal_perCapita, 'Type':'fatal'})\n",
    "df2 = pd.DataFrame({'Top_City': non_fatal_cities, 'Rank_mean': non_fatal_ranks,  'FARS_PerCapita': non_fatal_perCapita, 'Type':'non_fatal'})\n",
    "FARS_perCapita = pd.concat([df1,df2]).reset_index().drop(columns=['index'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we are preparing a dataframe for the fatal accidents and population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df for next visualization\n",
    "df1 = perCapita.sort_values(by=['Pop_mean'],ascending=False)[:10]\n",
    "df1['Type'] = 'Top Ten Biggest Cities'\n",
    "df2 = perCapita.sort_values(by=['FARS_PerCapita'],ascending=False)[:10]\n",
    "df2['Type'] = 'Top Ten Cities with Most Fatal Accidents'\n",
    "\n",
    "df = df1.append(df2).reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vis for Per Capita Fatal accidents in top cities in the US\n",
    "\n",
    "## Left\n",
    "fa = alt.Chart(df).mark_bar().encode(\n",
    "    y = alt.Y('Top_City', sort=alt.EncodingSortField(field=\"Rank_mean\", op='max'), axis=None),\n",
    "    x = alt.X('FARS_PerCapita', sort='descending',\n",
    "             axis=alt.Axis(title=None)),\n",
    "    color = alt.Color('Type', \n",
    "                      scale=alt.Scale(domain=['Top Ten Biggest Cities', 'Top Ten Cities with Most Fatal Accidents'],\n",
    "                                      range=['blue', 'orange']))\n",
    ")\n",
    "\n",
    "text = fa.mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    dx=-35  # Nudges text to right so it doesn't appear on top of the bar\n",
    ").encode(\n",
    "    text='FARS_PerCapita'\n",
    ")\n",
    "\n",
    "fatal = alt.layer(fa, text).properties(title='Fatal accidents per 100,000 people', width=350)\n",
    "\n",
    "## Mid\n",
    "col = alt.Chart(df).mark_bar().encode(\n",
    "    y=alt.Y('Top_City', sort=alt.SortField(field=\"Rank_mean\"), axis=None),\n",
    "    text=alt.Text('Top_City')).mark_text().properties(title='City', width=90)\n",
    "\n",
    "## Right\n",
    "fa = alt.Chart(df).mark_bar().encode(\n",
    "    y = alt.Y('Top_City', sort=alt.EncodingSortField(field=\"Rank_mean\", op='max'), axis=None),\n",
    "    x = alt.X('Pop_mean',\n",
    "             axis=alt.Axis(title=None)),\n",
    "    color = alt.Color('Type',\n",
    "                      scale=alt.Scale(domain=['Top Ten Biggest Cities', 'Top Ten Cities with Most Fatal Accidents'],\n",
    "                                      range=['blue', 'orange']),legend=alt.Legend(orient='bottom', labelLimit = 200))    \n",
    ")\n",
    "\n",
    "text = fa.mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    dx=5  # Nudges text to right so it doesn't appear on top of the bar\n",
    ").encode(\n",
    "    text='pop'\n",
    ")\n",
    "\n",
    "popu = alt.layer(fa, text).properties(title='City Population', width=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we can see here, the population is really not a considerable factor that causes fatalities, if any is probably an inverse relationship because we can see that the biggest cities have the lower fatalities than less populous cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fatal | col | popu).configure_view(strokeWidth=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's take a look at hospitals and fatal accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df for next visualization\n",
    "df1 = perCapita.sort_values(by=['Hospitals_PerCapita'],ascending=False)[:10]\n",
    "df1['Type'] = 'Top Ten Cities with Most Hospitals'\n",
    "df2 = perCapita.sort_values(by=['FARS_PerCapita'],ascending=False)[:10]\n",
    "df2['Type'] = 'Top Ten Cities with Most Fatal Accidents'\n",
    "tail = len(df) - 10\n",
    "df = df.drop(df.index[10:tail])\n",
    "df['Type'] = 'Top Ten Cities with Most Hospitals'\n",
    "df['Type'][10:] = 'Top Ten Cities with Most Fatal Accidents'\n",
    "df = df1.append(df2).reset_index().drop(columns=['index'])\n",
    "df.sort_values(by=['Hospitals_PerCapita'],ascending=False, inplace=True)\n",
    "df.drop(17, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vis for Per Capita Hospitals in top cities in the US\n",
    "\n",
    "## Left\n",
    "fa = alt.Chart(df).mark_bar().encode(\n",
    "    y = alt.Y('Top_City', sort=alt.EncodingSortField(field=\"index\", op='max'), axis=None),\n",
    "    x = alt.X('FARS_PerCapita', sort='descending',\n",
    "             axis=alt.Axis(title=None)),\n",
    "    color = alt.Color('Type', \n",
    "                      scale=alt.Scale(domain=['Top Ten Cities with Most Hospitals', 'Top Ten Cities with Most Fatal Accidents'],\n",
    "                                      range=['blue', 'orange']))\n",
    ")\n",
    "\n",
    "text = fa.mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    dx=-35  # Nudges text to right so it doesn't appear on top of the bar\n",
    ").encode(\n",
    "    text='FARS_PerCapita'\n",
    ")\n",
    "\n",
    "fatal = alt.layer(fa, text).properties(title='Fatal accidents per 100,000 people', width=350)\n",
    "\n",
    "## Mid\n",
    "col = alt.Chart(df).mark_bar().encode(\n",
    "    y=alt.Y('Top_City', sort=alt.SortField(field=\"index\"), axis=None),\n",
    "    text=alt.Text('Top_City')).mark_text().properties(title='City', width=90)\n",
    "\n",
    "## Right\n",
    "fa = alt.Chart(df).mark_bar().encode(\n",
    "    y = alt.Y('Top_City', sort=alt.EncodingSortField(field=\"index\", op='max'), axis=None),\n",
    "    x = alt.X('Hospitals_PerCapita',\n",
    "             axis=alt.Axis(title=None)),\n",
    "    color = alt.Color('Type',\n",
    "                      scale=alt.Scale(domain=['Top Ten Cities with Most Hospitals', 'Top Ten Cities with Most Fatal Accidents'],\n",
    "                                      range=['blue', 'orange']),\n",
    "                     legend=alt.Legend(orient='bottom', labelLimit = 200))    \n",
    ")\n",
    "\n",
    "text = fa.mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    dx=5  # Nudges text to right so it doesn't appear on top of the bar\n",
    ").encode(\n",
    "    text='Hospitals_PerCapita'\n",
    ")\n",
    "\n",
    "popu = alt.layer(fa, text).properties(title='Hospitals per 100,000 people', width=350)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we can see a small relationship of hospitals anc fatal accidents being the more hospitals the less accidents in a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fatal | col | popu).configure_view(strokeWidth=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With help from the hospitals dataset we can collect the response time in a given city. Let's take a look if it has any impact on fatal accidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are calculating the response time for for each accident in the FARS dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering records containing Not, Arr and Hosp Time\n",
    "FARS_hosp_time = FARS[(FARS['NOT_HOUR']!=99) & (FARS['NOT_HOUR']!=88) & \n",
    "                                      (FARS['ARR_HOUR']!=99) & (FARS['ARR_HOUR']!=88) & \n",
    "                                      (FARS['HOSP_HR']!=99) & (FARS['HOSP_HR']!=88)&\n",
    "                              (FARS['NOT_MIN']!=99)&(FARS['NOT_MIN']!=88)&\n",
    "                              (FARS['ARR_MIN']!=99)&(FARS['ARR_MIN']!=88)&\n",
    "                              (FARS['HOSP_MN']!=99)&(FARS['HOSP_MN']!=88)]\n",
    "\n",
    "FARS_hosp_time['Notification_Time'] = (pd.to_datetime(FARS_hosp_time['YEAR'].astype(str) + ':'+\n",
    "                                                      FARS_hosp_time['MONTH_x'].astype(str) + ':'+\n",
    "                                                      FARS_hosp_time['DAY_x'].astype(str) + ':'+\n",
    "                                                      FARS_hosp_time['NOT_HOUR'].astype(str) + ':' +\n",
    "                                                            FARS_hosp_time['NOT_MIN'].astype(str), \n",
    "                                                            format='%Y:%m:%d:%H:%M'))\n",
    "\n",
    "FARS_hosp_time['Arrival_Time'] = (pd.to_datetime(FARS_hosp_time['YEAR'].astype(str) + ':'+\n",
    "                                                 FARS_hosp_time['MONTH_x'].astype(str) + ':'+\n",
    "                                                 FARS_hosp_time['DAY_x'].astype(str) + ':'+\n",
    "                                                 FARS_hosp_time['ARR_HOUR'].astype(str) + ':' +\n",
    "                                                 FARS_hosp_time['ARR_MIN'].astype(str), \n",
    "                                                             format='%Y:%m:%d:%H:%M'))\n",
    "\n",
    "FARS_hosp_time['Hospital_Time'] = (pd.to_datetime(FARS_hosp_time['YEAR'].astype(str) + ':'+\n",
    "                                                      FARS_hosp_time['MONTH_x'].astype(str) + ':'+\n",
    "                                                      FARS_hosp_time['DAY_x'].astype(str) + ':'+\n",
    "                                                      FARS_hosp_time['HOSP_HR'].astype(str) + ':' +\n",
    "                                                           FARS_hosp_time['HOSP_MN'].astype(str), \n",
    "                                                            format='%Y:%m:%d:%H:%M'))\n",
    "\n",
    "\n",
    "# Calculate times for each accident.\n",
    "FARS_hosp_time['Time_to_Accident'] = (FARS_hosp_time['Arrival_Time'] - \n",
    "                                        FARS_hosp_time['Notification_Time'])\n",
    "\n",
    "FARS_hosp_time['Time_to_Hospital'] = (FARS_hosp_time['Hospital_Time'] - \n",
    "                                         FARS_hosp_time['Arrival_Time'])\n",
    "\n",
    "FARS_hosp_time['Total_Time'] = (FARS_hosp_time['Hospital_Time'] - \n",
    "                                         FARS_hosp_time['Notification_Time'])\n",
    "\n",
    "# Convert to seconds\n",
    "FARS_hosp_time['Time_to_Accident'] = FARS_hosp_time.apply(lambda row: row['Time_to_Accident'].seconds, axis=1)\n",
    "\n",
    "FARS_hosp_time['Time_to_Hospital'] = FARS_hosp_time.apply(lambda row: row['Time_to_Hospital'].seconds, axis=1)\n",
    "\n",
    "FARS_hosp_time['Total_Time'] = FARS_hosp_time.apply(lambda row: row['Total_Time'].seconds, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter the FARS data with the top cities only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_Hosp_Time_Top_Cities = filter_top_cities(FARS_hosp_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARS_Hosp_Time_Top_Cities = FARS_Hosp_Time_Top_Cities[['Top_City', 'Pop', 'Rank','Time_to_Accident', \n",
    "                                                       'Time_to_Hospital', 'Total_Time']]\n",
    "\n",
    "FARS_Hosp_Time_Top_Cities = FARS_Hosp_Time_Top_Cities.groupby(['Top_City', 'Pop']).agg({'Rank': ['count', 'mean'],\n",
    "                                                            'Pop': ['mean'],\n",
    "                                                            'Time_to_Accident': 'mean',\n",
    "                                                            'Time_to_Hospital': 'mean',\n",
    "                                                            'Total_Time': 'mean',})\n",
    "\n",
    "FARS_Hosp_Time_Top_Cities.columns = FARS_Hosp_Time_Top_Cities.columns.map('_'.join)\n",
    "FARS_Hosp_Time_Top_Cities.reset_index(inplace = True)\n",
    "FARS_Hosp_Time_Top_Cities['FARS_PerCapita'] = round((FARS_Hosp_Time_Top_Cities['Rank_count']/FARS_Hosp_Time_Top_Cities['Pop_mean'])*100000,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Average response time\n",
    "\n",
    "# 2 df will be created one for topten biggest cities and one for topten most fatal accidents citites\n",
    "\n",
    "df = FARS_Hosp_Time_Top_Cities.copy()\n",
    "df = df.loc[df['Top_City'].isin(non_fatal_cities)]\n",
    "df.reset_index(inplace=True)\n",
    "df['Type'] = 'Top Ten Non Fatal Accidents Cities'\n",
    "respTime = df.copy()\n",
    "\n",
    "####\n",
    "df = FARS_Hosp_Time_Top_Cities.copy()\n",
    "df = df.loc[df['Top_City'].isin(fatal_cities)]\n",
    "df = df.loc[df['Rank_mean'].isin(fatal_ranks)]\n",
    "df['Type'] = 'Top Ten Most Fatal Accidents Cities'\n",
    "respTime = respTime.append(df)\n",
    "respTime.reset_index()\n",
    "respTime.drop(columns=['index'], inplace=True)\n",
    "respTime.drop(2, inplace=True)\n",
    "\n",
    "\n",
    "respTime['pop'] = respTime.apply(lambda row: human_format(row['Pop']), axis=1) #Apply human_format function\n",
    "    \n",
    "respTime['Total_Time_Text'] = respTime.apply(lambda row: convert(row['Total_Time_mean']), axis=1) #Apply human_format function\n",
    "respTime['Time_to_Accident_Text'] = respTime.apply(lambda row: convert(row['Time_to_Accident_mean']), axis=1) #Apply human_format function\n",
    "respTime['Time_to_Hospital_Text'] = respTime.apply(lambda row: convert(row['Time_to_Hospital_mean']), axis=1) #Apply human_format function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt = pd.melt(respTime, id_vars =['Top_City', 'Pop', 'Rank_count', 'Rank_mean'], value_vars =['Time_to_Accident_mean','Time_to_Hospital_mean']) \n",
    "mlt = pd.merge(mlt, FARS_perCapita, how=\"outer\", on=[\"Top_City\"]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vis for average response time in top cities in the US\n",
    "\n",
    "## Left\n",
    "l = alt.Chart(mlt).mark_bar().encode(\n",
    "    y = alt.Y('Top_City', sort=alt.EncodingSortField(field=\"FARS_PerCapita\",order='ascending', op='max'), axis=None),\n",
    "    x = alt.X('FARS_PerCapita',sort='descending',\n",
    "             axis=alt.Axis(title=None)),\n",
    "    color = alt.Color('Type',\n",
    "                      scale=alt.Scale(domain=['non_fatal', 'fatal'],\n",
    "                                      range=['blue', 'orange']),\n",
    "                     legend=alt.Legend(orient='bottom', labelLimit = 200))  \n",
    ")\n",
    "\n",
    "text = l.mark_text(\n",
    "    align='right',\n",
    "    baseline='middle',\n",
    "    dx=-15 # Nudges text to right so it doesn't appear on top of the bar\n",
    ").encode(\n",
    "    text='max(FARS_PerCapita)'\n",
    ")\n",
    "\n",
    "left = alt.layer(l, text).properties(title='Fatal accidents per 100,000 people', width=350)\n",
    "\n",
    "\n",
    "## Mid\n",
    "col = alt.Chart(mlt).mark_bar().encode(\n",
    "    y=alt.Y('Top_City', sort=alt.SortField(field=\"FARS_PerCapita\",order='ascending'), axis=None),\n",
    "    text=alt.Text('Top_City')).mark_text().properties(title='City', width=90)\n",
    "\n",
    "### Right\n",
    "r = alt.Chart(mlt).mark_bar().encode(\n",
    "    y = alt.Y('Top_City', sort=alt.EncodingSortField(field=\"FARS_PerCapita\", order='ascending', op='max'), axis=None),\n",
    "    x = alt.X('value', stack='zero',\n",
    "             axis=alt.Axis(title=None)),\n",
    "    color = alt.Color('variable',\n",
    "                      scale=alt.Scale(domain=['Time_to_Hospital_mean', 'Time_to_Accident_mean'],\n",
    "                                      range=['mediumvioletred', 'purple']),\n",
    "                     legend=alt.Legend(orient='bottom', labelLimit = 200)\n",
    "                     ), \n",
    "    order = 'variable'\n",
    ")\n",
    "\n",
    "text = alt.Chart(mlt).mark_text(align='right', dx=-3, color='white').encode(\n",
    "    y=alt.Y('Top_City', sort=alt.EncodingSortField(field=\"FARS_PerCapita\", order='ascending', op='max'), axis=None),\n",
    "    x=alt.X('value', stack='zero'),\n",
    "    detail='value',\n",
    "    text=alt.Text('value', format='.1f')\n",
    ")\n",
    "\n",
    "\n",
    "right = alt.layer(r, text).properties(title='Response Time (seconds)', width=350).resolve_scale(color='independent')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mlt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we can see that response time is really not a factor on fatalities in a city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Top_City':['NY', 'Seattle', 'KC', 'Macon'], \n",
    "        'Age':[20, 21, 19, 18]} \n",
    "  \n",
    "# Create the pandas DataFrame \n",
    "df = pd.DataFrame(data, columns = ['Name', 'Age']) \n",
    "  \n",
    "# print dataframe. \n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(left | col | right).configure_view(strokeWidth=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = alt.Chart(mlt).mark_bar().encode(\n",
    "    y = alt.Y('Top_City', sort=alt.EncodingSortField(field=\"FARS_PerCapita\",order='ascending', op='max'), axis=None),\n",
    "    x = alt.X('FARS_PerCapita',sort='descending',\n",
    "             axis=alt.Axis(title=None)),\n",
    "    color = alt.Color('Type',\n",
    "                      scale=alt.Scale(domain=['non_fatal', 'fatal'],\n",
    "                                      range=['blue', 'orange']),\n",
    "                     legend=alt.Legend(orient='bottom', labelLimit = 200))  \n",
    ")\n",
    "\n",
    "text = l.mark_text(\n",
    "    align='right',\n",
    "    baseline='middle',\n",
    "    dx=-15 \n",
    ").encode(\n",
    "    text='max(FARS_PerCapita)'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perCapita.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alt.Chart(perCapita).mark_circle(size=60).encode(\n",
    "    x='Pop_mean',\n",
    "    y='FARS_PerCapita',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(perCapita).mark_circle(size=60).encode(\n",
    "    x='Hospitals_PerCapita',\n",
    "    y='FARS_PerCapita',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
